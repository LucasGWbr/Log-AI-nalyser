# ðŸ¤– Log AI Analyser

> **AnÃ¡lise inteligente de erros de software utilizando IA Generativa Local.**

O **Log AI Analyser** Ã© uma ferramenta Full-Stack que ingere logs de erro (Stack Traces), limpa os dados irrelevantes, verifica recorrÃªncias e utiliza um LLM (Llama 3) rodando localmente para diagnosticar a causa raiz e sugerir correÃ§Ãµes de cÃ³digo.

---

## ðŸš€ Diferenciais TÃ©cnicos

* **ðŸ”’ Privacidade Total:** A IA roda 100% local (Ollama). Nenhum dado sensÃ­vel sai da sua mÃ¡quina.
* **âš¡ Smart Caching:** Se o mesmo erro ocorrer novamente (mesmo com datas diferentes), a resposta Ã© retornada do banco em milissegundos, sem gastar processamento da IA.
* **ðŸ§¹ Filtro de RuÃ­do Inteligente:** Algoritmo capaz de limpar Timestamps e IDs variÃ¡veis de logs em Java, Python, Go, Node.js e Logs de Sistema, garantindo precisÃ£o no cache.
* **ðŸ›¡ï¸ SeguranÃ§a:** Otimizado para cortar logs gigantes e prevenir travamentos ou custos excessivos de tokens.

---

## ðŸ› ï¸ Tech Stack

### Backend
* **Java 21**
* **Spring Boot 3** (Web, Data JPA)
* **Spring AI** (IntegraÃ§Ã£o com LLMs)
* **PostgreSQL** (PersistÃªncia)
* **Ollama** (Servidor de InferÃªncia de IA)

### Frontend
* **React** (Vite)
* **Tailwind CSS** (EstilizaÃ§Ã£o Dark Mode)
* **Lucide React** (Ãcones)
* **Syntax Highlighter** (VisualizaÃ§Ã£o de cÃ³digo)

### Infraestrutura
* **Docker** & **Docker Compose**

---

## ðŸ“‹ PrÃ©-requisitos

VocÃª sÃ³ precisa de **uma** ferramenta instalada:

* [Docker Desktop](https://www.docker.com/products/docker-desktop/)

*(NÃ£o Ã© necessÃ¡rio instalar Java, Node.js ou PostgreSQL localmente).*

---

## âš¡ Como Executar o Projeto

Siga os passos abaixo para subir o ambiente completo.

### 1. Clonar o repositÃ³rio
```bash
git clone https://github.com/LucasGWbr/Log-AI-nalyser.git
cd log-ai-nalyser
```

### 2. Subir os containers
Este comando irÃ¡ compilar o Backend e Frontend e iniciar o Banco de Dados.
```bash
docker compose up -d --build
```

### 3. Baixar o Modelo de IA (Apenas na 1Âª vez)
O container do Ollama inicia vazio. Precisamos baixar o "cÃ©rebro" (Llama 3). Execute no terminal:
```bash
docker exec -it log-ai-ollama ollama run llama3
```
Aguarde o download (aprox. 4.7GB). Quando aparecer o prompt >>>, digite /bye para sair.

### 4. Acessar
    - Frontend: http://localhost:5173

    - Backend API: http://localhost:8080
